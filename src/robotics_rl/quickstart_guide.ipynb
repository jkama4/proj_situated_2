{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Situated AI Assignment 2: Robotics and Reinforcement Learning\n",
    "\n",
    "This notebook provides a quickstart for training RL agents on Gymnasium Robotics environments using RL Baselines3 Zoo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup\n",
    "\n",
    "Run these cells once to install dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install system dependencies (Colab only - skip if running locally)\n",
    "# !apt-get update && apt-get install -q -y swig cmake ffmpeg freeglut3-dev xvfb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setup virtual display for video recording (Colab only)\n",
    "# import os\n",
    "# os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
    "# os.environ['DISPLAY'] = ':1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mount your drive to the session\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install Python packages\n",
    "# !pip install -q rl-zoo3\n",
    "# !pip install -q -e git+https://github.com/Farama-Foundation/Gymnasium-Robotics.git#egg=gymnasium-robotics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create wrapper for record_video (rl_zoo3.record_video doesn't support --gym-packages)\n",
    "# with open('record_video.py', 'w') as f:\n",
    "#     f.write(\n",
    "#         '#!/usr/bin/env python\\n'\n",
    "#         'import gymnasium_robotics\\n'\n",
    "#         'import runpy\\n'\n",
    "#         'runpy.run_module(\"rl_zoo3.record_video\", run_name=\"__main__\")\\n'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Configure Hyperparameters\n",
    "\n",
    "RL Zoo expects hyperparameters in a YAML file. Modify these to experiment with different settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Wrapper.class_name of <class 'gymnasium.wrappers.common.TimeLimit'>>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import gymnasium_robotics\n",
    "\n",
    "gym.register_envs(gymnasium_robotics)\n",
    "\n",
    "env = gym.make(\"FetchReachDense-v4\") # (x,y,z) = [1.3419 0.7491 0.555] m are starting coords\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters saved to hyperparams.yaml\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "hyperparams = {\n",
    "    'FetchReachDense-v4': {\n",
    "        'n_timesteps': 1000,\n",
    "        'policy': 'MultiInputPolicy',\n",
    "        'noise_type': 'ornstein-uhlenbeck',\n",
    "        'noise_std': 0.5,\n",
    "        'gradient_steps': 1,\n",
    "        'train_freq': 1,\n",
    "        'learning_rate': 1e-3,\n",
    "        'batch_size': 256,\n",
    "        'policy_kwargs': \"dict(net_arch=[32, 32])\",\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('hyperparams.yaml', 'w') as f:\n",
    "    yaml.dump(hyperparams, f, sort_keys=False)\n",
    "\n",
    "print(\"Hyperparameters saved to hyperparams.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Train the Agent\n",
    "\n",
    "Train a DDPG agent on the FetchReachDense-v4 environment. Training logs are saved to `logs/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code in the terminal in ~/project_path/src/robotics_rl for training the agent\n",
    "\n",
    "```\n",
    "!python -m rl_zoo3.train --algo ddpg --env FetchReachDense-v4 \\\n",
    "    --gym-packages gymnasium_robotics -c hyperparams.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following for evaluating the agent\n",
    "\n",
    "```\n",
    "!python -m rl_zoo3.train --algo ddpg --env FetchReachDense-v4 \\\n",
    "    --gym-packages gymnasium_robotics -c hyperparams.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Evaluate the Agent\n",
    "\n",
    "Run the trained agent and see its performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m rl_zoo3.enjoy --algo ddpg --env FetchReachDense-v4 \\\n",
    "    --gym-packages gymnasium_robotics --no-render -n 500 -f logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Record and View Video\n",
    "\n",
    "Record a video of the trained policy to visually evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record_video.py is a wrapper that pre-loads gymnasium_robotics\n",
    "# (rl_zoo3.record_video doesn't support --gym-packages)\n",
    "!python record_video.py --algo ddpg --env FetchReachDense-v4 -f logs/ -n 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from pathlib import Path\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "def show_videos(video_path, prefix=\"\"):\n",
    "    \"\"\"Display MP4 videos from a folder in the notebook.\"\"\"\n",
    "    html = []\n",
    "    for mp4 in Path(video_path).glob(f\"{prefix}*.mp4\"):\n",
    "        video_b64 = base64.b64encode(mp4.read_bytes()).decode('ascii')\n",
    "        html.append(f'''<video alt=\"{mp4}\" autoplay loop controls style=\"height: 400px;\">\n",
    "            <source src=\"data:video/mp4;base64,{video_b64}\" type=\"video/mp4\" />\n",
    "        </video>''')\n",
    "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the recorded video\n",
    "# Update the path if your experiment ID differs (check logs/ddpg/ folder)\n",
    "show_videos('logs/ddpg/FetchReachDense-v4_1/videos/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Commands\n",
    "\n",
    "```bash\n",
    "# Train with a different algorithm\n",
    "python -m rl_zoo3.train --algo sac --env FetchReachDense-v4 --gym-packages gymnasium_robotics -c hyperparams.yaml\n",
    "\n",
    "# Train with a specific seed (for reproducibility)\n",
    "python -m rl_zoo3.train --algo ddpg --env FetchReachDense-v4 --gym-packages gymnasium_robotics -c hyperparams.yaml --seed 42\n",
    "\n",
    "# Load best model instead of final model\n",
    "python -m rl_zoo3.enjoy --algo ddpg --env FetchReachDense-v4 --gym-packages gymnasium_robotics -f logs/ --load-best\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robotics-rl-py3.13 (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
